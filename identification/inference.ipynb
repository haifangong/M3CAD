{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a284aac4",
   "metadata": {},
   "source": [
    "# M3CAD Identification Inference Demo\n",
    "\n",
    "This notebook demonstrates the inference process for the M3CAD identification model. It covers:\n",
    "1.  Loading pre-trained models (Antimicrobial, Toxin, etc.).\n",
    "2.  Loading sample data (Sequences and PDB voxels).\n",
    "3.  Performing predictions.\n",
    "4.  Visualizing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735b20a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:53:58.801311Z",
     "iopub.status.busy": "2026-01-23T17:53:58.797999Z",
     "iopub.status.idle": "2026-01-23T17:54:26.788797Z",
     "shell.execute_reply": "2026-01-23T17:54:26.780097Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbica/comp_space/gongha/micromamba/envs/torch29/lib/python3.14/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbica/comp_space/gongha/micromamba/envs/torch29/lib/python3.14/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import GDataset, ADataset\n",
    "from network import MMPeptide, SEQPeptide\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8054946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:26.815547Z",
     "iopub.status.busy": "2026-01-23T17:54:26.811574Z",
     "iopub.status.idle": "2026-01-23T17:54:27.297574Z",
     "shell.execute_reply": "2026-01-23T17:54:27.284918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cbica/comp_space/gongha/codes/M3CAD/identification/dataset.py:259: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  seq = str(row[1])\n",
      "\r",
      " 14%|██████████▏                                                             | 422/3000 [00:00<00:00, 4218.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████▋                                             | 1087/3000 [00:00<00:00, 5646.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████▋              | 2396/3000 [00:00<00:00, 9043.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████| 3000/3000 [00:00<00:00, 8265.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 3000 samples.\n",
      "DataLoader created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "# We will use a sample dataset. Ensure you have 'metadata/data_processed.csv' or similar.\n",
    "# Here we use GDataset which reads from a CSV path.\n",
    "\n",
    "data_path = 'gendata/v2_filter_r3.csv'  # Example path, adjust if needed\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"Data file {data_path} not found. Using a placeholder dataset for demonstration.\")\n",
    "    # You might want to point to an existing CSV or create a dummy one\n",
    "\n",
    "# Assuming we use GDataset for generated data or ADataset for training data\n",
    "try:\n",
    "    test_set = GDataset(path=data_path)\n",
    "    print(f\"Loaded dataset with {len(test_set)} samples.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load dataset: {e}\")\n",
    "    test_set = []\n",
    "\n",
    "if len(test_set) > 0:\n",
    "    valid_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "    print(\"DataLoader created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449221d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:27.316652Z",
     "iopub.status.busy": "2026-01-23T17:54:27.315047Z",
     "iopub.status.idle": "2026-01-23T17:54:28.056478Z",
     "shell.execute_reply": "2026-01-23T17:54:28.050067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from run/anti-mm-mlce1280.00250/model_1.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MMPeptide(\n",
       "  (v_encoder): ResNet3D(\n",
       "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
       "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (max_pool): MaxPool3d(kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential()\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential()\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
       "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
       "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "  )\n",
       "  (q_encoder): SEQ(\n",
       "    (rnn): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=50, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=50, out_features=1024, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (rnn_fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fusion): Linear(in_features=2304, out_features=6, bias=True)\n",
       "  (vox_fc): Linear(in_features=2048, out_features=6, bias=True)\n",
       "  (seq_fc): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "# Adjust number of classes based on task (e.g., 6 for anti, 1 for mic/toxin)\n",
    "num_classes = 6 \n",
    "model = MMPeptide(classes=num_classes).to(device)\n",
    "\n",
    "# Path to weights\n",
    "weight_path = 'run/anti-mm-mlce1280.00250/model_1.pth'\n",
    "\n",
    "if os.path.exists(weight_path):\n",
    "    model.load_state_dict(torch.load(weight_path, map_location=device))\n",
    "    print(f\"Loaded weights from {weight_path}\")\n",
    "else:\n",
    "    print(f\"Warning: Weight file not found at {weight_path}. Using random weights.\")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a3e310",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:28.074652Z",
     "iopub.status.busy": "2026-01-23T17:54:28.074304Z",
     "iopub.status.idle": "2026-01-23T17:54:28.324405Z",
     "shell.execute_reply": "2026-01-23T17:54:28.321625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete.\n"
     ]
    }
   ],
   "source": [
    "# Inference Loop\n",
    "results = []\n",
    "\n",
    "if len(test_set) > 0:\n",
    "    print(\"Starting inference...\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            if i >= 10: break # Limit to 10 samples for demo\n",
    "            \n",
    "            voxel, seq, exist_info, index = data\n",
    "            voxel = voxel.to(device)\n",
    "            seq = seq.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            pred, feature = model((voxel, seq))\n",
    "            \n",
    "            # Process result\n",
    "            pred_vals = pred.cpu().numpy().flatten()\n",
    "            results.append({\n",
    "                'Index': index.item() if isinstance(index, torch.Tensor) else index,\n",
    "                'Info': exist_info[0] if isinstance(exist_info, list) else exist_info,\n",
    "                'Predictions': pred_vals\n",
    "            })\n",
    "    \n",
    "    print(\"Inference complete.\")\n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7478ed28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:28.331982Z",
     "iopub.status.busy": "2026-01-23T17:54:28.331653Z",
     "iopub.status.idle": "2026-01-23T17:54:28.359108Z",
     "shell.execute_reply": "2026-01-23T17:54:28.355493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Index                                               Info  \\\n",
      "0       (EYCVKSYTKFYWNL,)  (127896,EYCVKSYTKFYWNL,0.99937861,0.798733688,...   \n",
      "1  (RYNPKWFCNFWTCLVTWFN,)  (131315,RYNPKWFCNFWTCLVTWFN,0.998720965,0.7747...   \n",
      "2       (KYMLKSYTEYYWQI,)  (124445,KYMLKSYTEYYWQI,0.991360021,0.45319928,...   \n",
      "3       (KPMIRSYMEFWWQI,)  (140972,KPMIRSYMEFWWQI,0.99246768,0.821931983,...   \n",
      "4       (KYNPKTFCDWWSML,)  (109446,KYNPKTFCDWWSML,0.998968741,0.864479621...   \n",
      "\n",
      "                                         Predictions  \n",
      "0  [-8.739532, 0.5637505, -0.5338131, -6.4296203,...  \n",
      "1  [-9.240669, 2.4427419, -3.3392594, -0.65752065...  \n",
      "2  [-8.387549, 0.4254674, 0.04264795, -5.8507676,...  \n",
      "3  [-9.023673, 2.5661252, 0.14928277, -6.693563, ...  \n",
      "4  [-7.6231074, 1.6117508, 0.43183252, -4.6166224...  \n",
      "Expanded results:\n",
      "                    Index                                               Info  \\\n",
      "0       (EYCVKSYTKFYWNL,)  (127896,EYCVKSYTKFYWNL,0.99937861,0.798733688,...   \n",
      "1  (RYNPKWFCNFWTCLVTWFN,)  (131315,RYNPKWFCNFWTCLVTWFN,0.998720965,0.7747...   \n",
      "2       (KYMLKSYTEYYWQI,)  (124445,KYMLKSYTEYYWQI,0.991360021,0.45319928,...   \n",
      "3       (KPMIRSYMEFWWQI,)  (140972,KPMIRSYMEFWWQI,0.99246768,0.821931983,...   \n",
      "4       (KYNPKTFCDWWSML,)  (109446,KYNPKTFCDWWSML,0.998968741,0.864479621...   \n",
      "\n",
      "    Class_0   Class_1   Class_2   Class_3   Class_4   Class_5  \n",
      "0 -8.739532  0.563751 -0.533813 -6.429620  1.767661 -5.214497  \n",
      "1 -9.240669  2.442742 -3.339259 -0.657521  1.104580 -7.390490  \n",
      "2 -8.387549  0.425467  0.042648 -5.850768  1.679783 -6.372781  \n",
      "3 -9.023673  2.566125  0.149283 -6.693563  3.034541 -6.998462  \n",
      "4 -7.623107  1.611751  0.431833 -4.616622  0.740702 -7.836303  \n",
      "Classification results saved to classification_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Display Results\n",
    "if results:\n",
    "    df_res = pd.DataFrame(results)\n",
    "    print(df_res.head())\n",
    "    \n",
    "    # Expand predictions if multi-class\n",
    "    preds = np.stack(df_res['Predictions'].values)\n",
    "    for c in range(preds.shape[1]):\n",
    "        df_res[f'Class_{c}'] = preds[:, c]\n",
    "    \n",
    "    print(\"Expanded results:\")\n",
    "    print(df_res.drop(columns=['Predictions']).head())\n",
    "\n",
    "\n",
    "# Save intermediate results\n",
    "df_res.to_csv('classification_results.csv', index=False)\n",
    "print('Classification results saved to classification_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10071351",
   "metadata": {},
   "source": [
    "# Regression Inference\n",
    "\n",
    "This section demonstrates how to use the model for regression tasks, such as predicting Minimum Inhibitory Concentration (MIC) or toxicity levels (if treated as continuous values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b95e9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:28.373084Z",
     "iopub.status.busy": "2026-01-23T17:54:28.372625Z",
     "iopub.status.idle": "2026-01-23T17:54:28.461128Z",
     "shell.execute_reply": "2026-01-23T17:54:28.451305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded regression weights from run/regression-seq-mse1280.00220/model_1.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SEQPeptide(\n",
       "  (q_encoder): SEQ(\n",
       "    (rnn): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=50, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=50, out_features=1024, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "    (rnn_fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fusion): Linear(in_features=2304, out_features=1, bias=True)\n",
       "  (vox_fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (seq_fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Regression Model\n",
    "# For regression tasks, we typically set classes=1 to get a single continuous output value.\n",
    "reg_model = SEQPeptide(classes=1).to(device)\n",
    "\n",
    "# Path to regression weights (Example: MIC prediction model)\n",
    "# Adjust this path to your trained regression model checkpoint\n",
    "reg_weight_path = 'run/regression-seq-mse1280.00220/model_1.pth'\n",
    "\n",
    "if os.path.exists(reg_weight_path):\n",
    "    reg_model.load_state_dict(torch.load(reg_weight_path, map_location=device))\n",
    "    print(f\"Loaded regression weights from {reg_weight_path}\")\n",
    "else:\n",
    "    print(f\"Warning: Regression weight file not found at {reg_weight_path}. Using random weights for demonstration.\")\n",
    "\n",
    "reg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dfd4aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:28.473810Z",
     "iopub.status.busy": "2026-01-23T17:54:28.473426Z",
     "iopub.status.idle": "2026-01-23T17:54:28.552244Z",
     "shell.execute_reply": "2026-01-23T17:54:28.548129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting regression inference...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression inference complete.\n"
     ]
    }
   ],
   "source": [
    "# Run Regression Inference\n",
    "reg_results = []\n",
    "\n",
    "if len(test_set) > 0:\n",
    "    print(\"Starting regression inference...\")\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_loader):\n",
    "            if i >= 10: break # Limit to 10 samples for demo\n",
    "            \n",
    "            voxel, seq, exist_info, index = data\n",
    "            voxel = voxel.to(device)\n",
    "            seq = seq.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            # For regression, the model returns a scalar value per sample\n",
    "            # Some implementations might return (pred, feature), let's handle that\n",
    "            output = reg_model((voxel, seq))\n",
    "            if isinstance(output, tuple):\n",
    "                pred_reg = output[0]\n",
    "            else:\n",
    "                pred_reg = output\n",
    "            \n",
    "            # Extract value\n",
    "            val = pred_reg.item() if pred_reg.numel() == 1 else pred_reg.cpu().numpy().flatten()\n",
    "            if isinstance(val, np.ndarray) and val.size == 1:\n",
    "                val = val.item()\n",
    "                \n",
    "            reg_results.append({\n",
    "                'Index': index.item() if isinstance(index, torch.Tensor) else index,\n",
    "                'Info': exist_info[0] if isinstance(exist_info, list) else exist_info,\n",
    "                'Predicted Value': val\n",
    "            })\n",
    "    \n",
    "    print(\"Regression inference complete.\")\n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50e8a9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T17:54:28.564459Z",
     "iopub.status.busy": "2026-01-23T17:54:28.564202Z",
     "iopub.status.idle": "2026-01-23T17:54:28.585976Z",
     "shell.execute_reply": "2026-01-23T17:54:28.580513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Index                                               Info  \\\n",
      "0       (EYCVKSYTKFYWNL,)  (127896,EYCVKSYTKFYWNL,0.99937861,0.798733688,...   \n",
      "1  (RYNPKWFCNFWTCLVTWFN,)  (131315,RYNPKWFCNFWTCLVTWFN,0.998720965,0.7747...   \n",
      "2       (KYMLKSYTEYYWQI,)  (124445,KYMLKSYTEYYWQI,0.991360021,0.45319928,...   \n",
      "3       (KPMIRSYMEFWWQI,)  (140972,KPMIRSYMEFWWQI,0.99246768,0.821931983,...   \n",
      "4       (KYNPKTFCDWWSML,)  (109446,KYNPKTFCDWWSML,0.998968741,0.864479621...   \n",
      "\n",
      "   Predicted Value  \n",
      "0         0.968370  \n",
      "1         0.907830  \n",
      "2         0.923516  \n",
      "3         0.855975  \n",
      "4         0.774706  \n",
      "Regression results saved to regression_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Display Regression Results\n",
    "if reg_results:\n",
    "    df_reg = pd.DataFrame(reg_results)\n",
    "    print(df_reg.head())\n",
    "\n",
    "# Save intermediate results\n",
    "df_reg.to_csv('regression_results.csv', index=False)\n",
    "print('Regression results saved to regression_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
