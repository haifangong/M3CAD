{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3CAD Generation Inference Demo\n",
    "\n",
    "This notebook demonstrates the inference process for the M3CAD generation model. It covers:\n",
    "1.  Loading a pre-trained model (VAE/WAE).\n",
    "2.  Generating novel peptide sequences conditioned on desired properties.\n",
    "3.  Analyzing the physicochemical properties of the generated sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataset import idx2ama, calculate_property\n",
    "from model import SEQVAE, MMVAE, SEQWAE, MMWAE\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Args:\n",
    "    gen_model = 'vae'  # 'vae' or 'wae'\n",
    "    model = 'seq'      # 'seq', 'mm_unet', or 'mm_mt'\n",
    "    classes = 4\n",
    "    seq_length = 30\n",
    "    use_augmentation = True\n",
    "    mask_prob = 0.1\n",
    "    condition = '1111' # Binary condition string\n",
    "    gen_number = 100   # Number of sequences to generate\n",
    "    # Path to your trained weights\n",
    "    weight_path = 'runs/checkpoints/seq1/weights/best.pth' \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_model(args):\n",
    "    if args.gen_model == 'vae':\n",
    "        if args.model == 'seq':\n",
    "            model = SEQVAE(args.classes, sequence_length=args.seq_length, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "        elif args.model == 'mm_unet':\n",
    "            model = MMVAE(args.classes, sequence_length=args.seq_length, use_encoder_feature=True, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "        elif args.model == 'mm_mt':\n",
    "            model = MMVAE(args.classes, sequence_length=args.seq_length, use_encoder_feature=False, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "    elif args.gen_model == 'wae':\n",
    "        if args.model == 'seq':\n",
    "            model = SEQWAE(args.classes, sequence_length=args.seq_length, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "        elif args.model == 'mm_unet':\n",
    "            model = MMWAE(args.classes, sequence_length=args.seq_length, use_encoder_feature=True, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "        elif args.model == 'mm_mt':\n",
    "            model = MMWAE(args.classes, sequence_length=args.seq_length, use_encoder_feature=False, use_augmentation=args.use_augmentation, mask_prob=args.mask_prob)\n",
    "    \n",
    "    if os.path.exists(args.weight_path):\n",
    "        model.load_state_dict(torch.load(args.weight_path, map_location=device))\n",
    "        print(f\"Loaded weights from {args.weight_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Weight file not found at {args.weight_path}. Using random weights.\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Loop\n",
    "condition_list = [float(bit) for bit in args.condition]\n",
    "condition = torch.tensor(condition_list).float().unsqueeze(0).to(device)\n",
    "\n",
    "generated_sequences = []\n",
    "properties_list = []\n",
    "count = 0\n",
    "seq_cache = set()\n",
    "\n",
    "print(f\"Generating {args.gen_number} sequences...\")\n",
    "start_time = time.time()\n",
    "\n",
    "while count < args.gen_number:\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn([condition.size(0), 32]).to(device)\n",
    "        recon_seq_indices, random_gen, ori_seq = model.inference(z, condition)\n",
    "        classify_result = model.cls_head(ori_seq.float())[0]\n",
    "        \n",
    "        # Basic filtering (optional)\n",
    "        if classify_result.any() < 0.75:\n",
    "           # continue\n",
    "           pass # Skip filtering for demo purposes if model is not fully trained\n",
    "\n",
    "        for batch_idx in range(recon_seq_indices.size(0)):\n",
    "            pred = recon_seq_indices[batch_idx]\n",
    "            if 21 in pred:\n",
    "                zero_indices = torch.where(pred == 21)[0][0].item()\n",
    "            elif 0 in pred:\n",
    "                zero_indices = torch.where(pred == 0)[0][0].item()\n",
    "            else:\n",
    "                zero_indices = -1\n",
    "            \n",
    "            valid_indices = pred[:zero_indices] if zero_indices != -1 else pred\n",
    "            pred_seq = [idx2ama[idx.item()] for idx in valid_indices]\n",
    "            seq_str = ''.join(pred_seq)\n",
    "\n",
    "            if 6 <= len(seq_str) <= 20 and seq_str not in seq_cache:\n",
    "                seq_cache.add(seq_str)\n",
    "                props = calculate_property(seq_str)\n",
    "                generated_sequences.append(seq_str)\n",
    "                properties_list.append(props)\n",
    "                count += 1\n",
    "                if count >= args.gen_number:\n",
    "                    break\n",
    "\n",
    "print(f\"Generation complete in {time.time() - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "property_names = [\n",
    "    'Gravy Score', 'Aliphatic Index', 'Aromaticity', 'Instability Index',\n",
    "    'Alpha Helix Fraction', 'Beta Helix Fraction', 'Turn Fraction',\n",
    "    'Charge at pH 7', 'Isoelectric Point', 'Charge Density',\n",
    "    'Average Hydrophobicity', 'Hydrophobic Moment'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(properties_list, columns=property_names)\n",
    "df.insert(0, 'Sequence', generated_sequences)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "metrics = ['Alpha Helix Fraction', 'Charge at pH 7', 'Hydrophobic Moment', 'Instability Index']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.histplot(df[metric], kde=True)\n",
    "    plt.title(f'Distribution of {metric}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

